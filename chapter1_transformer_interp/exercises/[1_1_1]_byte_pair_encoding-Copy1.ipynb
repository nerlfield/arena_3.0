{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f331be2f-1ac2-40cd-8402-53dfb37bc572",
   "metadata": {},
   "source": [
    "I want achieve:\n",
    "\n",
    "- vocabluary - the map of what pair of bytes were merged: text_corp -> f(x) -> utf8_bytes -> f(x) -> vocab\n",
    "- decode - code, vocab -> f_decode(x, y) -> string\n",
    "- encode - string -> f_encode(x) -> code, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "30577ea2-3021-4904-b931-775d751d154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"“Why?’‘Because it is too small. “Five feet high is the door, and three abreast [first written four abreast] may enter it” say the runes. But Pryftan could not creep in a hole that size, not even when he was a young dragon, certainly not after he had devoured so many maidens of the valley.’‘It seems a pretty big hole,’ piped Bilbo. He loved maps, and in the hall there was a large one of the County Round (where he lived), with all his favourite walks marked on it in red ink. He was so interested he forgot to be shy and keep his mouth shut. ‘How could such an enormous door’ (he was a hobbit, remember) ‘be secret?’‘Lots of ways,’ said Bl[adorthin], ‘but which one of them we don’t know without looking. At the top of the other side of the page there is a list of the dwarves, which includes ‘Gandalf’; and against this my father afterwards wrote in pencil: ‘NB Gandalf was originally chief Dwarf (=Thorin) and Gandalf was called Bladorthin.’ The names of the dwarves in The Hobbit were taken from verses of a very ancient Norse poem called Völuspá, where many dwarf-names are given, and among them Gandalf. The only other difference in this original list is that Oi appears for Ori (in the Völuspá there is the name Ái). – Bladorthin became the name of a long-dead king who is mentioned once in The Hobbit (p. 230) but nowhere else. From what it says on the map I should say that there is a closed door which looks just like the side of the mountain – the ordinary dwarf’s way (I think I am right?)’‘Quite,’ said Gandalf. ‘But this rather alters things. There are fourteen of us – unless you are coming, Bladorthin. I had thought of going up along Running River from the Long Lake – if we can get so far! – and so to the Ruins of Dale Town. But we none of us liked the idea of the Front Gate. The River runs out of that great door, and out of it the Dragon comes too. Far too often.’‘That would have been no good,’ said Bl[adorthin], ‘without a mighty warrior; even a hero. I tried to find one, but I had to fall back (I beg your pardon, but I am sure you will understand – dragon-slaying is not I believe your speciality) – to fall back on little Bilbo [first written Mr Baggins].’‘The burglar,’ said Dwalin. ‘Precisely,’ said Blad[orthin], not allowing Bilbo time to object. ‘I told you last Thursday it would have to be a burglary not a battle, and a burglar I promised to find. I hope no one is going to say I put the sign on the wrong door again.’ He frowned so frightfully at Bilbo that the little man daren’t say anything though he was bursting with questions.‘Warriors are very busy fighting one another in far lands,’ went on Bl[adorthin], ‘and in this neighbour-hood there are none or few [struck out: left, of men, dwarves, elves or hobbits], not to speak of heroes. Swords in the world are mostly blunt, and axes used on trees and shields for dish-covers, and dragons comfortably far-off. But burglary is I think indicated in any case by the presence of the back door.’‘What is your plan?’ they all said. ‘To go to the back door, sit on the step – and think of one – if one does not”\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "47671449-8cba-4dc0-81a0-591b3bb5890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"aaaBbaba\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c6e52b3-9bc9-432f-a573-cea0bff9b470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3212, [226, 128, 156, 87, 104, 121, 63, 226, 128, 153])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(text.encode('utf-8'))\n",
    "len(tokens), tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c996e3da-f9d9-4c3c-a650-a91590bdda40",
   "metadata": {},
   "source": [
    "If I want to get vocab, I need to:\n",
    "1. find two most frequent tokens\n",
    "2. add them to map (a, b): new_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35746ce6-c560-4270-8760-80b2ef7f9ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((101, 32), 105),\n",
       " ((32, 116), 75),\n",
       " ((116, 104), 73),\n",
       " ((104, 101), 63),\n",
       " ((116, 32), 58)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_freqs(tokens):\n",
    "    freq_stats = {}\n",
    "    for i, j in zip(tokens, tokens[1:]):\n",
    "        freq_stats[(i, j)] = freq_stats.get((i, j), 1) + 1\n",
    "    return freq_stats\n",
    "\n",
    "stats = get_freqs(tokens)\n",
    "sorted(stats.items(), key=lambda x: x[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a2d7448-5e89-44c6-802e-8165bad0b374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(101, 32): 256}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merges = {}\n",
    "max_freq_pair, frq = max(stats.items(), key=lambda x: x[1])\n",
    "merges[max_freq_pair] = 256\n",
    "merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eafce7d6-4567-42b0-8880-0472d2a15d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_tokens_by_parent(tokens, target, parent):\n",
    "    new_tokens = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i+1 < len(tokens) and (tokens[i], tokens[i+1]) == target:\n",
    "            new_tokens.append(parent)\n",
    "            i += 2\n",
    "        else:\n",
    "            new_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "    \n",
    "    return new_tokens\n",
    "\n",
    "new_tokens = replace_tokens_by_parent(tokens, max_freq_pair, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f06a2-65eb-472d-bba0-e5d7687400f1",
   "metadata": {},
   "source": [
    "Fit vocab:\n",
    "1. get tokens\n",
    "2. get freqs of tokens\n",
    "3. calculate max frequency pair\n",
    "4. replace\n",
    "5. repeat 2 step K times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b85d7e2-76aa-42cd-bf22-6bba5e542dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MERGES = 42\n",
    "\n",
    "tokens = list(text.encode('utf-8'))\n",
    "merges = {}\n",
    "\n",
    "for i in range(N_MERGES):\n",
    "    stats = get_freqs(tokens)\n",
    "    max_freq_pair, frq = max(stats.items(), key=lambda x: x[1])\n",
    "    new_token_id = 256 + i\n",
    "    merges[new_token_id] = max_freq_pair\n",
    "    tokens = replace_tokens_by_parent(tokens, max_freq_pair, new_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d7d676c-99bd-4566-a952-55847174474c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5129533678756477"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(text.encode('utf-8'))) / len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b34fc86a-2c10-4fb8-b25b-02513166b493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO WORLD!'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {i:bytes([i]) for i in range(256)}\n",
    "inv_merges = {v: k for k, v in merges.items()}\n",
    "\n",
    "for k, (p0, p1) in merges.items():\n",
    "    vocab[k] = vocab[p0] + vocab[p1]\n",
    "\n",
    "def decode(tokens):\n",
    "    return b\"\".join(vocab.get(t) for t in tokens).decode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "def encode(string):\n",
    "    tokens = list(string.encode('utf-8'))\n",
    "    while len(tokens) >= 2:\n",
    "        new_tokens = []\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            if i+1 < len(tokens) and (tokens[i], tokens[i+1]) in inv_merges:\n",
    "                new_tokens.append(inv_merges[tokens[i], tokens[i+1]])\n",
    "                i += 2\n",
    "            else:\n",
    "                new_tokens.append(tokens[i])\n",
    "                i += 1\n",
    "    \n",
    "        is_not_changed = len(tokens) == len(new_tokens)\n",
    "        tokens = new_tokens\n",
    "        if is_not_changed:\n",
    "            break\n",
    "    return tokens\n",
    "\n",
    "decode(encode(\"HELLO WORLD!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4c782e2-3df3-4137-8968-7a95dd65f3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(encode(text)) == text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb687d-723a-4cd4-aaa8-741b6b4159ca",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "https://www.youtube.com/watch?v=zduSFxRajkE&t=3417s&ab_channel=AndrejKarpathy\n",
    "\n",
    "https://github.com/karpathy/minbpe/blob/master/exercise.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3e3a72-5d94-4971-90b6-e7d2dac87d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(name):\n",
    "    with open(name, \"r\") as file:\n",
    "        return file.read()\n",
    "\n",
    "text = read_file(\"taylorswift.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "43b313e7-6de2-4bb4-91e6-d483955d6457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "class BasicTokenizer:\n",
    "    def __init__(self):\n",
    "        self.vocab, self.merges, self.inv_merges = {}, {}, {}\n",
    "        pass\n",
    "\n",
    "    def get_freqs(self, tokens):\n",
    "        # Using Counter for efficient frequency calculation\n",
    "        token_pairs = zip(tokens, tokens[1:])\n",
    "        return Counter(token_pairs)\n",
    "\n",
    "    def replace_tokens_by_parent(self, tokens, target, parent):\n",
    "        # Improved token replacement for efficiency\n",
    "        new_tokens = []\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            if i+1 < len(tokens) and (tokens[i], tokens[i+1]) == target:\n",
    "                new_tokens.append(parent)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_tokens.append(tokens[i])\n",
    "                i += 1\n",
    "        return new_tokens\n",
    "    \n",
    "    def train(self, text, vocab_size, verbose=False):\n",
    "        tokens = list(text.encode('utf-8'))\n",
    "        vocab_size -= 256\n",
    "        \n",
    "        merges = {}\n",
    "        \n",
    "        progress_bar = tqdm(range(vocab_size)) if verbose else range(vocab_size)\n",
    "        \n",
    "        for i in progress_bar:\n",
    "            stats = self.get_freqs(tokens)\n",
    "            max_freq_pair, _ = max(stats.items(), key=lambda x: x[1])\n",
    "            new_token_id = 256 + i\n",
    "            merges[new_token_id] = max_freq_pair\n",
    "            tokens = self.replace_tokens_by_parent(tokens, max_freq_pair, new_token_id)\n",
    "        \n",
    "        inv_merges = {v: k for k, v in merges.items()}\n",
    "        vocab = {i: bytes([i]) for i in range(256)}\n",
    "        \n",
    "        for k, (p0, p1) in merges.items():\n",
    "            vocab[k] = vocab[p0] + vocab[p1]\n",
    "        \n",
    "        self.vocab, self.merges, self.inv_merges = vocab, merges, inv_merges\n",
    "        \n",
    "    def encode(self, text):\n",
    "        # given a string text, return the token ids\n",
    "        text_bytes = text.encode(\"utf-8\") # raw bytes\n",
    "        ids = list(text_bytes) # list of integers in range 0..255\n",
    "        while len(ids) >= 2:\n",
    "            stats = self.get_freqs(ids)\n",
    "            pair = min(stats, key=lambda p: self.inv_merges.get(p, float(\"inf\")))\n",
    "            if pair not in self.inv_merges:\n",
    "                break\n",
    "            idx = self.inv_merges[pair]\n",
    "            ids = self.replace_tokens_by_parent(ids, pair, idx)\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        return b\"\".join(self.vocab.get(t) for t in ids).decode('utf-8', errors=\"replace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "efc37401-c4a1-45b6-a9b5-280736fda647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f474bc2bbca540abaa93cdd5c152aec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(name):\n",
    "    with open(name, \"r\", encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "# long_text = read_file('01 - The Fellowship Of The Ring.txt')\n",
    "long_text = read_file('taylorswift.txt')\n",
    "\n",
    "basic_tokenizer = BasicTokenizer()\n",
    "basic_tokenizer.train(long_text, vocab_size=300, verbose=True)\n",
    "\n",
    "basic_tokenizer.decode(basic_tokenizer.encode(long_text)) == long_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d87dffa2-cda3-4184-8b23-f7e949141544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 : H\n",
      "101 : e\n",
      "108 : l\n",
      "108 : l\n",
      "111 : o\n",
      "33 : !\n",
      "32 :  \n",
      "72 : H\n",
      "111 : o\n",
      "119 : w\n",
      "32 :  \n",
      "271 : ar\n",
      "256 : e \n",
      "121 : y\n",
      "111 : o\n",
      "117 : u\n",
      "63 : ?\n",
      "32 :  \n",
      "70 : F\n",
      "101 : e\n",
      "98 : b\n",
      "114 : r\n",
      "117 : u\n",
      "271 : ar\n",
      "273 : y \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: #baf7e1;\">H</span><span style=\"background-color: #f7c1ba;\">e</span><span style=\"background-color: #f7f4ba;\">l</span><span style=\"background-color: #f7f4ba;\">l</span><span style=\"background-color: #e3f7ba;\">o</span><span style=\"background-color: #babcf7;\">!</span><span style=\"background-color: #bac3f7;\"> </span><span style=\"background-color: #baf7e1;\">H</span><span style=\"background-color: #e3f7ba;\">o</span><span style=\"background-color: #baf7cb;\">w</span><span style=\"background-color: #bac3f7;\"> </span><span style=\"background-color: #baf7d9;\">ar</span><span style=\"background-color: #f7e6ba;\">e </span><span style=\"background-color: #baf7d9;\">y</span><span style=\"background-color: #e3f7ba;\">o</span><span style=\"background-color: #baf7bc;\">u</span><span style=\"background-color: #d5f7ba;\">?</span><span style=\"background-color: #bac3f7;\"> </span><span style=\"background-color: #baf7d2;\">F</span><span style=\"background-color: #f7c1ba;\">e</span><span style=\"background-color: #f7bac8;\">b</span><span style=\"background-color: #cdf7ba;\">r</span><span style=\"background-color: #baf7bc;\">u</span><span style=\"background-color: #baf7d9;\">ar</span><span style=\"background-color: #baf7e8;\">y </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install seaborn\n",
    "from IPython.display import display, HTML\n",
    "import colorsys\n",
    "\n",
    "def soft_pastel_colors(num_colors):\n",
    "    # Generate colors in HSL space and convert to RGB, then to HEX for softer, muted tones\n",
    "    colors = []\n",
    "    for i in range(num_colors):\n",
    "        # HSL: Hue, Saturation (lower for softness), Lightness (higher for pastel)\n",
    "        hue = i / num_colors\n",
    "        # saturation = 0.35  # Lower saturation for softness\n",
    "        saturation = 0.80  # Lower saturation for softness\n",
    "        lightness = 0.85  # Higher lightness for pastel\n",
    "        rgb = colorsys.hls_to_rgb(hue, lightness, saturation)\n",
    "        hex_color = \"#{:02x}{:02x}{:02x}\".format(int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255))\n",
    "        colors.append(hex_color)\n",
    "    return colors\n",
    "\n",
    "def get_color(token, color_list):\n",
    "    return color_list[token % len(color_list)]\n",
    "\n",
    "def print_colored_text(text, color_list):\n",
    "    encoded_text = basic_tokenizer.encode(text)\n",
    "    html_string = ''\n",
    "    \n",
    "    for token in encoded_text:\n",
    "        color = get_color(token, color_list)\n",
    "        decoded_char = basic_tokenizer.decode([token])  # Assuming this returns a string\n",
    "        print(f\"{token} : {decoded_char}\")\n",
    "        html_string += f'<span style=\"background-color: {color};\">{decoded_char}</span>'\n",
    "    \n",
    "    display(HTML(html_string))\n",
    "\n",
    "# Example usage\n",
    "# color_list = ['#FFDDDD', '#DDFFDD', '#DDDDFF', '#FFFFDD', '#DDFFFF', '#FFDDFF']\n",
    "color_list =  soft_pastel_colors(50)\n",
    "\n",
    "# This will display the colored text in a Jupyter Notebook cell\n",
    "print_colored_text(\"Hello! How are you? February \", color_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "281479f6-459c-492b-b6cd-e42b565cd9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72,\n",
       " 101,\n",
       " 108,\n",
       " 108,\n",
       " 111,\n",
       " 33,\n",
       " 32,\n",
       " 72,\n",
       " 111,\n",
       " 119,\n",
       " 32,\n",
       " 271,\n",
       " 256,\n",
       " 121,\n",
       " 111,\n",
       " 117,\n",
       " 63,\n",
       " 32,\n",
       " 70,\n",
       " 101,\n",
       " 98,\n",
       " 114,\n",
       " 117,\n",
       " 271,\n",
       " 273]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_tokenizer.encode(\"Hello! How are you? February \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a9b6b-db2e-4e06-8199-fd207b4a4747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
